{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from gurobipy import Model, GRB, quicksum\n",
    "import numpy as np\n",
    "import math\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_or_tract = 'county' # 'tract' or 'county'\n",
    "state = 'WA' # 'RI', 'WA', 'AR', 'AK'\n",
    "\n",
    "distance_data = 'data/{}/{}_distances.csv'.format(state, county_or_tract)\n",
    "population_data = 'data/{}/{}_population.txt'.format(state, county_or_tract)\n",
    "features_data = 'data/{}/{}_features.csv'.format(state, county_or_tract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_df = pd.read_csv(distance_data)\n",
    "with open(population_data) as f:\n",
    "    pop = f.read().splitlines()\n",
    "\n",
    "pop_df = []\n",
    "for p in pop[1:]:\n",
    "    pop_df.append(p.split(' '))\n",
    "pop_df = pd.DataFrame(pop_df, columns=[\"id\", \"pop\"])\n",
    "\n",
    "feature_df = pd.read_csv(features_data, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vis data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if county_or_tract == 'county':\n",
    "    path_to_shapefile = 'geo_files/{}_geo_files/{}/{}_counties'.format(state, county_or_tract, state)\n",
    "    path_to_centers_shapefile = 'geo_files/{}_geo_files/{}/{}_centers'.format(state, county_or_tract, state)\n",
    "else:\n",
    "    path_to_shapefile = 'geo_files/{}_geo_files/{}/{}_tracts'.format(state, county_or_tract, state)\n",
    "    path_to_centers_shapefile = 'geo_files/{}_geo_files/{}/{}_centers'.format(state, county_or_tract, state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_matrix = np.zeros((len(feature_df), len(feature_df)))\n",
    "adj_df = pd.DataFrame(zero_matrix)\n",
    "id_map = {}\n",
    "for i, id in enumerate(feature_df[0]):\n",
    "    id_map[id] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node, adj_list in zip(feature_df[0], feature_df[2]):\n",
    "    node_idx = id_map[node]\n",
    "    for adj in adj_list.split(','):\n",
    "        try:\n",
    "            adj_idx = id_map[int(adj[1:])]\n",
    "        except KeyError:\n",
    "            adj_idx = id_map[int(adj)]\n",
    "        adj_df.iloc[node_idx, adj_idx] = 1\n",
    "adj_matrix = adj_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df['pop'] = pd.to_numeric(pop_df['pop'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert adjacency matrix to graph\n",
    "import networkx as nx\n",
    "G = nx.Graph()\n",
    "for i in range(len(feature_df[0])):\n",
    "    G.add_node(i)\n",
    "for i in range(len(adj_matrix)):\n",
    "    for j in range(len(adj_matrix)):\n",
    "        if adj_matrix[i, j] == 1:\n",
    "            G.add_edge(i, j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exact cut-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L = 2440006 , U = 2696848 , k = 3\n"
     ]
    }
   ],
   "source": [
    "DG = nx.DiGraph(G)\n",
    "model = Model(\"districting_model\")\n",
    "model._DG = DG\n",
    "n = len(DG.nodes) \n",
    "k = 3  # Number of districts\n",
    "population = [i for i in pop_df['pop'].values]\n",
    "deviation = 0.1\n",
    "L = math.ceil((1-deviation/2)*sum(population)/k)\n",
    "U = math.floor((1+deviation/2)*sum(population)/k)\n",
    "print(\"L =\",L,\", U =\",U,\", k =\",k)\n",
    "\n",
    "maxp = max(population[i] for i in G.nodes)\n",
    "if k==1 or maxp>U:\n",
    "    print(\"k=\",k,\", max{ p_v | v in V } =\",maxp,\", U =\",U,end='.')\n",
    "    sys.exit(\"Aborting early, either due to trivial instance or overtly infeasible instance.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter TimeLimit to value 300\n",
      "Gurobi Optimizer version 11.0.1 build v11.0.1rc0 (win64 - Windows 10.0 (19045.2))\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i7-8750H CPU @ 2.20GHz, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 6 physical cores, 12 logical processors, using up to 12 threads\n",
      "\n",
      "Optimize a model with 8230 rows, 8789 columns and 42454 nonzeros\n",
      "Model fingerprint: 0x28708e16\n",
      "Variable types: 7176 continuous, 1613 integer (1613 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+06]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 3e+00]\n",
      "Using branch priorities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\20193217\\AppData\\Local\\Temp\\ipykernel_22056\\1930322012.py:32: DeprecationWarning: Calling quicksum on a tupledict is deprecated, use .sum() instead.\n",
      "  m.setObjective(quicksum(m._Y), GRB.MINIMIZE )\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presolve removed 1678 rows and 428 columns\n",
      "Presolve time: 0.30s\n",
      "Presolved: 6552 rows, 8361 columns, 38761 nonzeros\n",
      "Crushed 1474 out of 1521 user cuts to presolved model\n",
      "Variable types: 6758 continuous, 1603 integer (1603 binary)\n",
      "\n",
      "Root relaxation: objective 2.401833e+00, 9614 iterations, 3.05 seconds (2.74 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0    2.40183    0 1406          -    2.40183      -     -    4s\n",
      "H    0     0                      92.0000000    2.40183  97.4%     -    5s\n",
      "     0     0    2.86985    0 1404   92.00000    2.86985  96.9%     -   18s\n",
      "H    0     0                      34.0000000    2.86985  91.6%     -   18s\n",
      "H    0     0                      30.0000000    2.86985  90.4%     -   18s\n",
      "     0     0    2.98449    0 1419   30.00000    2.98449  90.1%     -   28s\n",
      "     0     0    3.00884    0 1397   30.00000    3.00884  90.0%     -   34s\n",
      "     0     0    3.01254    0 1415   30.00000    3.01254  90.0%     -   35s\n",
      "     0     0    3.01270    0 1415   30.00000    3.01270  90.0%     -   35s\n",
      "     0     0    3.19023    0 1431   30.00000    3.19023  89.4%     -   50s\n",
      "     0     0    3.27247    0 1386   30.00000    3.27247  89.1%     -   57s\n",
      "H    0     0                      23.0000000    3.33683  85.5%     -   63s\n",
      "     0     0    3.33683    0 1388   23.00000    3.33683  85.5%     -   63s\n",
      "     0     0    3.34947    0 1407   23.00000    3.34947  85.4%     -   87s\n",
      "H    0     0                      19.0000000    3.35564  82.3%     -   91s\n",
      "     0     0    3.35564    0 1419   19.00000    3.35564  82.3%     -   91s\n",
      "     0     0    3.35731    0 1397   19.00000    3.35731  82.3%     -   96s\n",
      "     0     0    3.35757    0 1428   19.00000    3.35757  82.3%     -   97s\n",
      "     0     0    3.46436    0 1343   19.00000    3.46436  81.8%     -  109s\n",
      "     0     0    3.48383    0 1340   19.00000    3.48383  81.7%     -  112s\n",
      "     0     0    3.48744    0 1346   19.00000    3.48744  81.6%     -  115s\n",
      "     0     0    3.48908    0 1338   19.00000    3.48908  81.6%     -  116s\n",
      "     0     0    3.48958    0 1351   19.00000    3.48958  81.6%     -  117s\n",
      "     0     0    3.55840    0 1380   19.00000    3.55840  81.3%     -  131s\n",
      "     0     0    3.57832    0 1360   19.00000    3.57832  81.2%     -  136s\n",
      "     0     0    3.58326    0 1379   19.00000    3.58326  81.1%     -  138s\n",
      "     0     0    3.58503    0 1394   19.00000    3.58503  81.1%     -  142s\n"
     ]
    }
   ],
   "source": [
    "m = Model()\n",
    "m._DG = DG\n",
    "m._X = m.addVars(DG.nodes, DG.nodes, vtype=GRB.BINARY)\n",
    "\n",
    "# DG = m._DG\n",
    "# Each vertex i assigned to one district\n",
    "m.addConstrs(quicksum(m._X[i,j] for j in DG.nodes) == 1 for i in DG.nodes)\n",
    "    \n",
    "# Pick k centers\n",
    "m.addConstr(quicksum(m._X[j,j] for j in DG.nodes) == k)\n",
    "\n",
    "# Population balance: population assigned to vertex j should be in [L,U], if j is a center\n",
    "m.addConstrs(quicksum(population[i] * m._X[i,j] for i in DG.nodes) <= U * m._X[j,j] for j in DG.nodes)\n",
    "m.addConstrs(quicksum(population[i] * m._X[i,j] for i in DG.nodes) >= L * m._X[j,j] for j in DG.nodes)\n",
    "\n",
    "# Add coupling inequalities for added model strength\n",
    "couplingConstrs = m.addConstrs(m._X[i,j] <= m._X[j,j] for i in DG.nodes for j in DG.nodes)\n",
    "\n",
    "# Make them user cuts\n",
    "for i in DG.nodes:\n",
    "    for j in DG.nodes:\n",
    "        couplingConstrs[i,j].Lazy = -1\n",
    "\n",
    "# Set branch priority on center vars\n",
    "for j in DG.nodes:\n",
    "    m._X[j,j].BranchPriority=1   \n",
    "\n",
    "# Y[i,j] = 1 if edge {i,j} is cut\n",
    "m._Y = m.addVars(G.edges, vtype=GRB.BINARY)\n",
    "\n",
    "m.addConstrs( m._X[i,v]-m._X[j,v] <= m._Y[i,j] for i,j in G.edges for v in G.nodes)\n",
    "m.setObjective(quicksum(m._Y), GRB.MINIMIZE )\n",
    "\n",
    "m._callback = None\n",
    "m._population = population\n",
    "m._U = U\n",
    "m._k = k\n",
    "m._base = 'hess'\n",
    "m._numLazyCuts = 0\n",
    "m._numCallbacks = 0\n",
    "\n",
    "# F[j,u,v] tells how much flow (from source j) is sent across arc (u,v)\n",
    "F = m.addVars( DG.nodes, DG.edges, vtype=GRB.CONTINUOUS)\n",
    "\n",
    "def most_possible_nodes_in_one_district(population, U):\n",
    "    cumulative_population = 0\n",
    "    num_nodes = 0\n",
    "    for ipopulation in sorted(population):\n",
    "        cumulative_population += ipopulation\n",
    "        num_nodes += 1\n",
    "        if cumulative_population > U:\n",
    "            return num_nodes - 1\n",
    "        \n",
    "# compute big-M    \n",
    "M = most_possible_nodes_in_one_district(m._population, m._U) - 1\n",
    "\n",
    "m.addConstrs(quicksum(F[j,u,j] for u in DG.neighbors(j)) == 0 for j in DG.nodes)\n",
    "m.addConstrs(quicksum( F[j,u,i]-F[j,i,u] for u in DG.neighbors(i) ) == m._X[i,j] for i in DG.nodes for j in DG.nodes if i!=j)\n",
    "m.addConstrs(quicksum( F[j,u,i] for u in DG.neighbors(i) ) <= M * m._X[i,j] for i in DG.nodes for j in DG.nodes if i!=j)\n",
    "\n",
    "m.setParam(GRB.Param.TimeLimit, 300)\n",
    "m.optimize()\n",
    "\n",
    "# Check if the model is infeasible\n",
    "if model.status == GRB.INFEASIBLE:\n",
    "    print('The model is infeasible; computing IIS')\n",
    "    model.computeIIS()\n",
    "    model.write(\"model.ilp\")\n",
    "\n",
    "# Output the results\n",
    "for v in model.getVars():\n",
    "    if v.x > 0.5:\n",
    "        print(f\"{v.varName}: {v.x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ j for j in DG.nodes if m._X[j,j].x > 0.5 ]\n",
    "districts = [ [ i for i in DG.nodes if m._X[i,j].x > 0.5 ] for j in labels]\n",
    "print(\"best solution (found) =\",districts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cluster_list(clusters):\n",
    "    # Find the maximum number to determine the size of the cluster list\n",
    "    max_number = max(max(cluster) for cluster in clusters)\n",
    "    # Initialize the cluster list with a placeholder indicating unassigned\n",
    "    cluster_list = [-1] * (max_number + 1)\n",
    "    # Populate the cluster list with the cluster numbers\n",
    "    for cluster_number, cluster in enumerate(clusters):\n",
    "        for number in cluster:\n",
    "            cluster_list[number] = cluster_number\n",
    "    return cluster_list\n",
    "\n",
    "# Generate the cluster list\n",
    "cluster_list = create_cluster_list(districts)\n",
    "print(cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf_counties_or_tracts = gpd.read_file(f\"{path_to_shapefile}.shp\")\n",
    "gdf_centers = gpd.read_file(f\"{path_to_centers_shapefile}.shp\")\n",
    "\n",
    "gdf_centers['cluster'] = cluster_list\n",
    "# gdf_centers = gdf_centers.merge(pop_df, left_on='id', right_on='id')\n",
    "gdf_centers = pd.concat([gdf_centers, pop_df], axis=1, join='inner')\n",
    "gdf_centers['markersize'] = gdf_centers['pop'].astype(int) / gdf_centers['pop'].astype(int).max() * 500 \n",
    "\n",
    "# Merge cluster assignments to counties\n",
    "gdf_counties_or_tracts = gdf_counties_or_tracts.merge(gdf_centers[['GEOID20', 'cluster']], on='GEOID20')\n",
    "\n",
    "# Plot the counties with colors based on the cluster assignments\n",
    "fig, ax = plt.subplots(figsize=(20, 30))\n",
    "gdf_counties_or_tracts.plot(ax=ax, column='cluster', categorical=True, legend=True, edgecolor='black')\n",
    "\n",
    "# Annotate the plot with the node numbers\n",
    "# for x, y, label in zip(gdf_centers.geometry.x, gdf_centers.geometry.y, gdf_centers.index):\n",
    "#     ax.annotate(label, xy=(x, y), xytext=(3,3), textcoords=\"offset points\")\n",
    "\n",
    "# Optional: Add legend title\n",
    "ax.legend(title='Cluster')\n",
    "# ax.set_xlim(-180,-90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total population and the expected population per district\n",
    "total_population = sum(population for node, population in G.nodes(data='population'))\n",
    "expected_population = total_population / k\n",
    "\n",
    "# Calculate the actual population per district\n",
    "actual_population = [sum(G.nodes[node]['population'] for node in G.nodes if x[node, k].x > 0.5) for k in range(K)]\n",
    "\n",
    "# Calculate the MSE of the population per district\n",
    "mse_population = np.mean([(actual - expected_population) ** 2 for actual in actual_population])\n",
    "\n",
    "# Calculate the number of cut edges\n",
    "cut_edges = sum(G.edges[edge]['weight'] for edge in G.edges if x[edge[0], k].x + x[edge[1], k].x == 1 for k in range(K))\n",
    "\n",
    "print(f\"MSE of population per district: {mse_population}\")\n",
    "print(f\"Number of cut edges: {cut_edges}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
